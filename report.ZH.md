# 面向 LCA 检索的领域向量模型微调与检索性能评估

## 摘要

面向生命周期评价（LCA）检索场景，构建了从原始 Tidas 结构化数据到 Markdown 文档与查询生成的管线，基于 Qwen3-Embedding-0.6B 进行对比学习微调，并在统一缓存向量上完成性能评估。实验表明，微调模型在头部与长尾检索指标上显著优于原始模型和多路云端向量模型，说明领域化微调能够有效纠正通用模型的排序偏好并提升覆盖。

## 1. 引言

通用向量模型在开放领域表现良好，但在 LCA 等专业场景中，语义偏好往往与域内需求不一致：例如 “steel” 查询期望优先生产或地域相关信息，但通用模型可能将合金或近义词混排。LCA 文档通常包含多字段长描述（地理、技术路径、时间等），排序时需要兼顾领域约束。为此，本文探索领域微调与统一评测流程，以量化微调收益并获得可复现的检索性能。

**领域向量模型的意义**  
从认知科学视角，大语言模型具备通用推理能力但缺乏特定领域的长期记忆，其效用依赖外部上下文。微调后的 LCA 领域向量模型可以充当“外部记忆”的智能索引，从海量专业知识中快速、准确地检索并注入上下文，实现“通用推理能力（大模型）+ 专业知识检索（领域向量模型）”的协同。这一架构模拟了人类专家的“广泛认知框架 + 深度专业知识”模式，使 AI 系统在保持灵活性的同时获得领域深度。

## 2. 数据与预处理

- **来源与格式**：数据来自 TianGong LCA（原始为 Tidas 结构化格式），转换为含 process/flow/metadata 的 Markdown 文档，保留关键信息（UUID、版本、地理、技术描述等）。  
- **数据规模**：训练集 17,037 条 query-doc，评测集查询 1,893，语料 3,786（qrels 同样 1,893），均由 Markdown + LLM 生成查询后清洗、去重、拆分得到。  
- **查询生成**：对每个文档使用大模型生成多组查询，保留查询文本与对应的文档标识（dataset_uuid|version）。  
- **对齐与去重**：构造文档主键 `doc_id = dataset_uuid[|version]`，对 `(query, doc_id)` 去重，文档层面再次去重以形成检索语料。  
- **负采样**：针对每个查询，从不同 doc_id 的文档中随机采样 10 条文本作为负例，可选择性加入难负例。  
- **数据划分与输出**：以固定随机种子划分训练/测试（测试占比 10%），生成训练集（query, pos, neg, prompt, doc_id）以及评测文件（test queries、corpus、qrels）。本次评测集规模：查询 1,893，语料 3,786。

## 3. 模型与训练

- **基座模型**：Qwen3-Embedding-0.6B。  
- **目标与损失**：对比学习（MultipleNegativesRankingLoss），批内其他样本充当负例，最大序列长度 1024。  
- **超参数**：训练轮次 2，学习率 1e-5，批大小 8，warmup 比例 0.1，权重衰减 0.01，采用 bf16（硬件不支持时回退 fp32），定期日志与检查点保存。  
- **训练策略**：单卡禁用自动数据并行以避免意外分布式模式；多卡可使用分布式加速。模型输出保存在本地供后续编码与评测。

## 4. 编码与评测协议

- **向量缓存**：对测试集的查询与语料一次性编码并保存，避免跨模型重复推理。缓存内容包含向量、ID 映射及元信息。  
- **检索过程**：基于向量的内积相似度，使用平坦索引检索 Top-100，保持与不同模型缓存一致的流程。  
- **指标**：计算 NDCG、MAP、Recall、Precision、MRR，K ∈ {1, 5, 10, 50, 100}，所有指标取查询级平均。  
- **对照组**：原始模型（raw）、微调模型（ft）以及多路云端模型（qwen3-embedding-8b/4b、bge-m3、codestral）。

## 5. 模型说明

- **raw（Qwen3-Embedding-0.6B）**：7×10^8 参数量级的通用中文/多语向量模型，使用对比学习和大规模语料训练，适合中短文本语义检索。  
- **ft（lca-qwen3-embedding）**：在 TianGong LCA 域数据上微调的 Qwen3-Embedding-0.6B，目标是对齐领域偏好与排序。  
- **qwen3-embedding-8b / 4b（云端）**：基于 Qwen3 家族的大容量云端向量模型，支持多语言和较长上下文，8B 版本在语义区分与鲁棒性上优于 4B。  
- **bge-m3（云端）**：BAAI bge 系列多语模型，强调跨领域兼容性与稳健性。  
- **codestral-embed-2505（云端）**：Mistral 家族的嵌入模型，重点在代码/技术语料的表征能力，兼具通用文本检索效果。

## 6. 指标解释

- **NDCG@K**：折损累积增益的归一化，衡量相关文档的排序位置，越高越好。  
- **MAP@K**：平均精确率，关注前 K 个结果中相关文档的命中位置。  
- **MRR@K**：首个相关文档的倒数排名均值，强调“最早命中”能力。  
- **Recall@K**：前 K 个结果召回的相关文档比例，反映覆盖度。  
- **Precision@K**：前 K 个结果中相关文档的占比，反映结果纯度。  
综合解读：NDCG/MAP/MRR 体现排序质量与命中位置，Recall 体现覆盖，Precision 体现纯度；实际检索需兼顾头部命中（如 NDCG@10、MRR@10）与长尾覆盖（Recall@50/100）。

## 7. 实验结果

**关键指标（@10）**

| 模型 | NDCG@10 | Recall@10 | MRR@10 | MAP@10 |
| --- | --- | --- | --- | --- |
| raw | 0.5808 | 0.7200 | 0.5367 | 0.5367 |
| ft | **0.7623** | **0.9049** | **0.7163** | **0.7163** |
| codestral | 0.6628 | 0.8045 | 0.6180 | 0.6180 |
| qwen8b | 0.5905 | 0.7369 | 0.5442 | 0.5442 |
| qwen4b | 0.5836 | 0.7290 | 0.5377 | 0.5377 |
| bge | 0.5839 | 0.7264 | 0.5388 | 0.5388 |

**长尾表现（@100）**

| 模型 | NDCG@100 | Recall@100 |
| --- | --- | --- |
| raw | 0.6171 | 0.8922 |
| ft | **0.7826** | **0.9947** |
| codestral | 0.6872 | 0.9171 |
| qwen8b | 0.6258 | 0.9033 |
| qwen4b | 0.6164 | 0.8822 |
| bge | 0.6156 | 0.8743 |

## 8. 分析

1. **微调收益**：相较原始模型，微调在排序质量与覆盖上同时提升（NDCG@10 +31.2%，Recall@10 +25.7%，MRR@10 +33.5%；Recall@100 +11.5%），说明领域化表征显著减少了通用模型的偏好误差。  
2. **云端对照**：codestral 表现居次但仍落后微调模型，其余云端模型仅带来边际增益，显示领域微调的重要性。  
3. **头部与长尾兼顾**：长尾 Recall 的提升表明模型不仅在前几个结果排序更稳健，也能覆盖更多相关文档，适合专业检索场景。

## 9. 结论与展望

本研究表明，在 LCA 专业检索中，领域化向量微调不仅提升头部排序，更显著改善长尾覆盖，证实“通用推理 + 领域记忆”架构的可行性与价值。微调后的模型可作为默认检索后端，为后续基于 RAG 或混合检索的应用奠定坚实向量基础。

展望方向包括：进一步挖掘领域难负例与对抗式扰动以提升判别力；在更大底座模型上重训并对齐量化/归一化策略以提高工业可部署性；引入统计显著性检验与分场景分层评测，增强结论的稳健性与可解释性。同时，可将“领域向量 + 大模型”联合作为记忆与推理的协同体系，探索跨领域迁移与在线自适应更新，以支持更动态、更精准的专业检索场景。
